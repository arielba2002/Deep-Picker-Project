{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielba2002/Deep-Picker-Project/blob/16-preprocessed-datasets-are-ready-for-model-training-and-testing/DeepPicker_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iFUlpH1KGl1"
      },
      "source": [
        "This Notebook main goal is to orginize the scraped data to a tensor structure ready for train/test splitting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# INSTALL/IMPORT PACKAGES\n"
      ],
      "metadata": {
        "id": "Jw_gSFNyiPJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "GYdUY10RVIXD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Raw Data"
      ],
      "metadata": {
        "id": "OjgcyLqTiVvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fXvCt4mJ0bB",
        "outputId": "2325743d-600d-4082-f174-3cc5c42fcd30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "{\n",
            "    \"id\": 2603,\n",
            "    \"playerName\": \"JaVale McGee\",\n",
            "    \"position\": \"C\",\n",
            "    \"age\": 32,\n",
            "    \"games\": 68,\n",
            "    \"gamesStarted\": 68,\n",
            "    \"minutesPg\": 1130.0,\n",
            "    \"fieldGoals\": 195,\n",
            "    \"fieldAttempts\": 306,\n",
            "    \"fieldPercent\": 0.637,\n",
            "    \"threeFg\": 3,\n",
            "    \"threeAttempts\": 6,\n",
            "    \"threePercent\": 0.5,\n",
            "    \"twoFg\": 192,\n",
            "    \"twoAttempts\": 300,\n",
            "    \"twoPercent\": 0.64,\n",
            "    \"effectFgPercent\": 0.642,\n",
            "    \"ft\": 53,\n",
            "    \"ftAttempts\": 82,\n",
            "    \"ftPercent\": 0.646,\n",
            "    \"offensiveRb\": 125,\n",
            "    \"defensiveRb\": 265,\n",
            "    \"totalRb\": 390,\n",
            "    \"assists\": 37,\n",
            "    \"steals\": 36,\n",
            "    \"blocks\": 94,\n",
            "    \"turnovers\": 55,\n",
            "    \"personalFouls\": 159,\n",
            "    \"points\": 446,\n",
            "    \"team\": \"LAL\",\n",
            "    \"season\": 2020,\n",
            "    \"playerId\": \"mcgeeja01\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define potential paths for the shared folder\n",
        "search_paths = [\n",
        "    \"/content/drive/My Drive\",            # My Drive\n",
        "    \"/content/drive/My Drive/Shortcuts\"  # Shortcuts in My Drive\n",
        "]\n",
        "\n",
        "# Define the shared folder name\n",
        "shared_folder_name = \"Deep-Picker-Project\"\n",
        "\n",
        "# Search for the folder in \"My Drive\"\n",
        "data_drive_dir = None\n",
        "for path in search_paths:\n",
        "    possible_path = os.path.join(path, shared_folder_name)\n",
        "    if os.path.exists(possible_path):\n",
        "        data_drive_dir = possible_path\n",
        "        break\n",
        "\n",
        "if not data_drive_dir:\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find the shared folder '{shared_folder_name}' in 'My Drive' or its shortcuts.\"\n",
        "    )\n",
        "\n",
        "# Define paths to raw data and metadata\n",
        "data_path = f\"{data_drive_dir}/Model Training/Data/raw_data.json\"\n",
        "metadata_path = f\"{data_drive_dir}/Model Training/Data/metadata.json\"\n",
        "# Import Data Json\n",
        "with open(data_path, 'r') as json_data:\n",
        "    data = json.load(json_data)\n",
        "\n",
        "# Import Metadata Json\n",
        "with open(metadata_path, 'r') as json_metadata:\n",
        "    metadata = json.load(json_metadata)\n",
        "\n",
        "print(json.dumps(data['LAL_2020']['players'][8], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preproccessing"
      ],
      "metadata": {
        "id": "Hdm_HVCIjK3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# DEFINE GLOBAL CONSTANTS\n",
        "# ==============================\n",
        "unwanted_stats = [\"id\", \"playerName\", \"team\", \"season\", \"playerId\", \"gamesStarted\"]\n",
        "per_game_stats = [\"points\", \"assists\", \"steals\", \"blocks\", \"turnovers\",\n",
        "                  \"personalFouls\", \"offensiveRb\", \"defensiveRb\", \"totalRb\",\n",
        "                  \"fieldGoals\", \"fieldAttempts\", \"threeFg\", \"threeAttempts\",\n",
        "                  \"twoFg\", \"twoAttempts\", \"ft\", \"ftAttempts\"]\n",
        "per_minute_stats = per_game_stats\n",
        "\n",
        "# Specify teams and ranges to remove\n",
        "team_year_filters = {\n",
        "    \"TOT\": None,          # Remove all seasons of TOT\n",
        "}"
      ],
      "metadata": {
        "id": "hNWVAkoDaDeI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1. CREATE PLAYERS DF\n",
        "# ==============================\n",
        "def create_players_df(team_data, team_key):\n",
        "    \"\"\"\n",
        "    Converts the nested dictionary structure for a single team_season\n",
        "    into a pandas DataFrame of player statistics, along with a labels list.\n",
        "\n",
        "    :param team_data: Dictionary containing a single team's season data.\n",
        "    :param team_key: The team-season key (e.g., \"PHO_2024\").\n",
        "    :return: (df, labels) -> DataFrame of player stats, and a labels list.\n",
        "    \"\"\"\n",
        "    labels = team_data.get(\"labels\", [])\n",
        "    player_list = team_data.get(\"players\", [])\n",
        "    df = pd.DataFrame(player_list)\n",
        "\n",
        "    # Extract team and season information from the team_key\n",
        "    team_name, season = team_key.split(\"_\")\n",
        "    df[\"team\"] = team_name\n",
        "    df[\"season\"] = int(season)\n",
        "\n",
        "    return df, labels\n",
        "\n",
        "# ==============================\n",
        "# 2. STAT REMOVAL\n",
        "# ==============================\n",
        "def remove_unwanted_stats(df, stats_to_remove):\n",
        "    \"\"\"\n",
        "    Removes a list of unwanted statistic columns from the DataFrame.\n",
        "\n",
        "    :param df: Original player statistics DataFrame.\n",
        "    :param stats_to_remove: List of column names to remove.\n",
        "    :return: DataFrame with specified columns removed.\n",
        "    \"\"\"\n",
        "    df = df.drop(columns=stats_to_remove, errors='ignore')\n",
        "    return df\n",
        "\n",
        "# ==============================\n",
        "# 3. PER-GAME NORMALIZATION\n",
        "# ==============================\n",
        "def per_game_normalize(df, per_game_cols, games_col=\"games\"):\n",
        "    \"\"\"\n",
        "    Performs per-game normalization on specified columns by dividing\n",
        "    their values by the 'games' column.\n",
        "\n",
        "    :param df: Player statistics DataFrame.\n",
        "    :param per_game_cols: List of columns to convert to per-game values.\n",
        "    :param games_col: Column name for the number of games.\n",
        "    :return: DataFrame with specified columns converted to per-game stats.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col in per_game_cols:\n",
        "        df[col] = df.apply(lambda row: row[col] / row[games_col] if row[games_col] != 0 else 0, axis=1)\n",
        "    return df\n",
        "\n",
        "# ==============================\n",
        "# NORMALIZE PLAYER STATS TO PER-MINUTES BASIS\n",
        "# ==============================\n",
        "def per_minute_normalize(df, per_minute_cols, minutes_col=\"minutesPg\"):\n",
        "    \"\"\"\n",
        "    Normalizes specified per-game stats to a per-minute basis.\n",
        "\n",
        "    :param df: Player statistics DataFrame.\n",
        "    :param per_minute_cols: List of columns already normalized to per-game values.\n",
        "    :param minutes_col: Column name for the minutes per game.\n",
        "    :return: DataFrame with specified columns normalized to per-minute stats.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col in per_minute_cols:\n",
        "        df[col] = df.apply(\n",
        "            lambda row: row[col] / row[minutes_col] if row[minutes_col] != 0 else 0, axis=1\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# ==============================\n",
        "# 4. MIN-MAX SCALING\n",
        "# ==============================\n",
        "def minmax_scale_df(df):\n",
        "    \"\"\"\n",
        "    Scales all numeric columns of the DataFrame to the [0, 1] range using MinMaxScaler.\n",
        "    Non-numeric columns are left as is.\n",
        "\n",
        "    :param df: DataFrame of stats.\n",
        "    :return: (scaled_df, scaler) -> scaled DataFrame and the fitted MinMaxScaler object.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    scaler = MinMaxScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "    return df, scaler\n",
        "\n",
        "# ==============================\n",
        "# 5. PREPARE FINAL X, Y (SINGLE TEAM)\n",
        "# ==============================\n",
        "def prepare_team_input_and_labels(df, labels):\n",
        "    \"\"\"\n",
        "    Prepares the final input (X) and labels (Y) for a single team.\n",
        "    :param df: Processed DataFrame (scaled, etc.).\n",
        "    :param labels: Placeholder for future labels (currently empty or partial).\n",
        "    :return: (X, Y) where X is a numpy array, Y is a numpy array of labels.\n",
        "    \"\"\"\n",
        "    X = df.to_numpy()\n",
        "    Y = np.array(labels) if labels else np.array([])\n",
        "    return X, Y\n",
        "\n",
        "# ==============================\n",
        "# 6. END-TO-END PIPELINE (SINGLE TEAM)\n",
        "# ==============================\n",
        "def preprocess_team_season_data(team_season_data,\n",
        "                                team_key,\n",
        "                                stats_to_remove,\n",
        "                                per_game_stats,\n",
        "                                per_minute_stats,\n",
        "                                games_col='games',\n",
        "                                minutes_col='minutesPg'):\n",
        "    \"\"\"\n",
        "    End-to-end pipeline to preprocess a single team_season entry.\n",
        "    1. Convert to DataFrame\n",
        "    2. Remove unwanted stats\n",
        "    3. Per-game normalization\n",
        "    4. Per-minute normalization\n",
        "    5. MinMax scale\n",
        "    6. Return (X, Y, scaler)\n",
        "    \"\"\"\n",
        "    # Convert team data to a DataFrame\n",
        "    df, labels = create_players_df(team_season_data, team_key)\n",
        "\n",
        "    # Remove unwanted stats\n",
        "    df = remove_unwanted_stats(df, stats_to_remove)\n",
        "\n",
        "    # Normalize per-game stats\n",
        "    df = per_game_normalize(df, per_game_stats, games_col)\n",
        "\n",
        "    # Normalize per-minute stats (on already per-game normalized stats)\n",
        "    df = per_minute_normalize(df, per_minute_stats, minutes_col)\n",
        "\n",
        "    # MinMax scaling\n",
        "    df, scaler = minmax_scale_df(df)\n",
        "\n",
        "    # Prepare final X and Y arrays\n",
        "    X, Y = prepare_team_input_and_labels(df, labels)\n",
        "    return X, Y, scaler"
      ],
      "metadata": {
        "id": "pbhnI3W0jgDi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# EXAMPLE USAGE FOR A SINGLE TEAM\n",
        "# ==============================\n",
        "team_key = \"LAL_2020\"\n",
        "\n",
        "X_pho, Y_pho, scaler_pho = preprocess_team_season_data(\n",
        "    data[team_key],\n",
        "    team_key=team_key,\n",
        "    stats_to_remove=unwanted_stats,\n",
        "    per_game_stats=per_game_stats,\n",
        "    per_minute_stats=per_minute_stats,\n",
        ")\n",
        "\n",
        "print(\"Single team X shape:\", X_pho.shape)\n",
        "print(\"Single team Y:\", Y_pho)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSg7dtrHkAu-",
        "outputId": "f140f515-1279-4aaf-8761-eb98bd079ac0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single team X shape: (20, 26)\n",
            "Single team Y: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_multiple_teams(all_teams_data,\n",
        "                              stats_to_remove,\n",
        "                              per_game_stats,\n",
        "                              per_minute_stats,\n",
        "                              teams_to_remove=None,\n",
        "                              games_col='games',\n",
        "                              minutes_col='minutesPg',\n",
        "                              max_players_per_team=None):\n",
        "    \"\"\"\n",
        "    Preprocesses multiple team_season entries at once and produces a 3D array (X) and labels (Y).\n",
        "\n",
        "    :param all_teams_data: Dict of many team_season entries, e.g. {\"PHO_2024\": {...}, \"LAL_2024\": {...}, ...}.\n",
        "    :param stats_to_remove: List of columns to remove.\n",
        "    :param per_game_stats: List of columns to normalize per game.\n",
        "    :param per_minute_stats: List of columns already normalized to per-game, to further normalize to per-minute.\n",
        "    :param teams_to_remove: Dict of team names to year ranges to remove. (Default: None)\n",
        "    :param games_col: Name of the column containing the number of games. (Default: 'games')\n",
        "    :param minutes_col: Name of the column containing minutes per game. (Default: 'minutesPg')\n",
        "    :param max_players_per_team: Maximum number of players to include per team (pads with zeros if fewer).\n",
        "                                 If None, use the largest number of players in the dataset.\n",
        "    :return: (X, Y, scaler) where:\n",
        "             X: 3D numpy array with shape (n_teams, max_players_per_team, n_features).\n",
        "             Y: 1D numpy array of team labels (if available).\n",
        "             scaler: The fitted MinMaxScaler used for scaling.\n",
        "    \"\"\"\n",
        "    all_teams_X = []\n",
        "    all_labels = []\n",
        "    feature_scaler = None\n",
        "\n",
        "    # 1. Preprocess each team using the single-team pipeline\n",
        "    for team_key, team_data in all_teams_data.items():\n",
        "        # Skip teams in `teams_to_remove`\n",
        "        if teams_to_remove:\n",
        "            team_name, season = team_key.split(\"_\")\n",
        "            season = int(season)\n",
        "\n",
        "            # If the team is in the filter, check the year range\n",
        "            if team_name in teams_to_remove:\n",
        "                year_range = teams_to_remove[team_name]\n",
        "                if year_range is None or (year_range[0] <= season <= year_range[1]):\n",
        "                    continue\n",
        "\n",
        "        # Use the single-team preprocessing pipeline\n",
        "        X_team, Y_team, scaler = preprocess_team_season_data(\n",
        "            team_season_data=team_data,\n",
        "            team_key=team_key,\n",
        "            stats_to_remove=stats_to_remove,\n",
        "            per_game_stats=per_game_stats,\n",
        "            per_minute_stats=per_minute_stats,\n",
        "            games_col=games_col,\n",
        "            minutes_col=minutes_col\n",
        "        )\n",
        "\n",
        "        # Save the scaler for reference\n",
        "        if feature_scaler is None:\n",
        "            feature_scaler = scaler\n",
        "\n",
        "        # Add team X and Y to the respective lists\n",
        "        all_teams_X.append(X_team)\n",
        "        all_labels.append(Y_team)\n",
        "\n",
        "    # Determine max players per team for consistent shape\n",
        "    if max_players_per_team is None:\n",
        "        max_players_per_team = max([team.shape[0] for team in all_teams_X])\n",
        "\n",
        "    # 2. Pad teams to have consistent player counts\n",
        "    padded_teams_X = []\n",
        "    for X_team in all_teams_X:\n",
        "        if X_team.shape[0] < max_players_per_team:\n",
        "            # Pad with zeros if fewer players\n",
        "            padding = np.zeros((max_players_per_team - X_team.shape[0], X_team.shape[1]))\n",
        "            padded_team = np.vstack([X_team, padding])\n",
        "        else:\n",
        "            # Truncate if more players than allowed\n",
        "            padded_team = X_team[:max_players_per_team]\n",
        "        padded_teams_X.append(padded_team)\n",
        "\n",
        "    # Convert to a 3D numpy array\n",
        "    X = np.stack(padded_teams_X)  # Shape: (n_teams, max_players_per_team, n_features)\n",
        "\n",
        "    # Convert Y to a 1D numpy array (team-level labels, if applicable)\n",
        "    Y = np.array(all_labels)\n",
        "\n",
        "    return X, Y, feature_scaler"
      ],
      "metadata": {
        "id": "6m1EkX8DkJNQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 8. EXAMPLE WITH MULTIPLE TEAMS\n",
        "# ==============================\n",
        "\"\"\"\n",
        "If you had multiple teams in the dictionary, you could do something like this:\n",
        "\n",
        "team_season_data = {\n",
        "    \"PHO_2024\": {...},\n",
        "    \"LAL_2024\": {...},\n",
        "    \"MIL_2024\": {...},\n",
        "    ... etc. ...\n",
        "}\n",
        "\n",
        "Below, we only have \"PHO_2024\". For demonstration, let's just reuse the same data\n",
        "to pretend we have 2 entries. In a real case, you'd replace these duplicates with\n",
        "actual different team data.\n",
        "\"\"\"\n",
        "\n",
        "# Mock multiple teams by duplicating the single-team data structure:\n",
        "mock_all_teams_data = {\n",
        "    \"PHO_2024\": data[\"PHO_2024\"],\n",
        "    \"LAL_2020\": data[\"LAL_2020\"]\n",
        "}\n",
        "\n",
        "X_all, Y_all, scaler_all = preprocess_multiple_teams(\n",
        "    all_teams_data=mock_all_teams_data, # Specified to run on mock data\n",
        "    stats_to_remove=unwanted_stats,\n",
        "    per_game_stats=per_game_stats,\n",
        "    per_minute_stats=per_minute_stats,\n",
        "    teams_to_remove=team_year_filters,\n",
        ")\n",
        "\n",
        "print(\"\\n*** All Teams Combined ***\")\n",
        "print(\"Combined X shape:\", X_all.shape)\n",
        "print(\"Combined Y shape:\", Y_all.shape)\n",
        "print(\"Combined X:\", X_all[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1VExhlakKG8",
        "outputId": "234e8910-8128-43c3-b460-4299d934d591"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** All Teams Combined ***\n",
            "Combined X shape: (2, 20, 26)\n",
            "Combined Y shape: (2, 0)\n",
            "Combined X: ['PF' 0.15384615384615374 0.5416666666666666 0.16414686825053995\n",
            " 0.1256283244070518 0.05064497414447084 1.0000000000000002\n",
            " 0.06218079040015867 0.041255516437744826 0.423 0.18307135419249268\n",
            " 0.04825902137810148 1.0 1.0 0.012892348886795258 0.01633030858994066\n",
            " 0.6836581709145427 0.03385068015404704 0.16660881638320027\n",
            " 0.08695393464570833 0.03203252838796053 0.01586750632220955\n",
            " 0.5516437744830663 0.01633030858994066 0.033321763276640055\n",
            " 0.07333994872722222]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 9. FINAL ALL DATA PREPROCCESSING\n",
        "# ==============================\n",
        "\n",
        "X_all, Y_all, scaler_all = preprocess_multiple_teams(\n",
        "    all_teams_data=data, # specified to run on all data\n",
        "    stats_to_remove=unwanted_stats,\n",
        "    per_game_stats=per_game_stats,\n",
        "    per_minute_stats=per_minute_stats,\n",
        "    teams_to_remove=team_year_filters,\n",
        ")\n",
        "\n",
        "print(\"\\n*** All Teams Combined ***\")\n",
        "print(\"Combined X shape:\", X_all.shape)\n",
        "print(\"Combined Y shape:\", Y_all.shape)\n",
        "print(\"Combined X:\", X_all[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzUhFQ5AgLbW",
        "outputId": "913390b0-1cac-469a-ee9e-931a642d1904"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** All Teams Combined ***\n",
            "Combined X shape: (861, 20, 26)\n",
            "Combined Y shape: (861, 0)\n",
            "Combined X: ['PF' 0.08333333333333326 0.9620253164556962 0.4688021354688022\n",
            " 0.025745548165629694 0.032330925647810434 0.30909090909090864 0.0\n",
            " 0.0010995494529071016 0.0 0.025745548165629694 0.03612086998498176\n",
            " 0.33532934131736514 0.23999999999999977 0.026594793678037618\n",
            " 0.033522849173997 0.4849094567404427 0.09617392548094116\n",
            " 0.026088822141171426 0.040310853655629454 0.0 0.009833369091039119\n",
            " 0.09445142571081211 0.007291219695344347 0.012803046556532933\n",
            " 0.02594152789926229]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}